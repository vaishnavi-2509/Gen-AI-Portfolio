<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>GEN-AI Portfolio</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }

    /* Navbar styles */
    nav {
      background-color: #2c3e50;
      color: white;
      /* position: fixed; */
      top: 0;
      /* width: 100%; */
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 10px 30px !important;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      z-index: 1000;
    }

    .logo {
      font-size: 24px;
      font-weight: bold;
      color: #00bcd4;
    }

    .logo span {
      color: white;
    }

    nav ul {
      list-style: none;
      display: flex;
    }

    nav ul li {
      margin-left: 20px;
    }

    nav ul li a {
      text-decoration: none;
      color: white;
      font-size: 16px;
      font-weight: 500;
      transition: color 0.3s;
    }

    nav ul li a:hover {
      color: #00bcd4;
    }

    .pdf-container {
      flex: 1;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .button-link {
      display: inline-block;
      padding: 10px 20px;
      font-size: 16px;
      font-weight: bold;
      color: white;
      background-color: #4285F4;
      text-decoration: none;
      border-radius: 5px;
      transition: background-color 0.3s;
    }

    .button-link:hover {
      background-color: #357ae8;
    }

    /* Section styles */
    section {
      /* height: 100vh; */
      padding: 60px 20px;
      display: flex;
      align-items: center;
      justify-content: center;
      background-color: #f4f4f4;
      border-bottom: 1px solid #ddd;
      scroll-margin-top: 80px; /* Ensures content doesn't hide under the navbar */
    }

    section:nth-child(even) {
      background-color: #eaeaea;
    }

    #introduction { background-color: white; }
    #report { background-color: white }
    #ppt { background-color: white; }
    #result { background-color: white; }
  </style>
</head>
<body>
  <nav>
    <div class="logo">GEN-<span>AI</span></div>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#report">Report</a></li>
      <li><a href="#ppt">PPT</a></li>
      <li><a href="#result">Result</a></li>
    </ul>
  </nav>

  <div style="padding:10px 60px; width:60%; margin:0 auto; ">
    <h1>About Me</h1>
      <p>Hello! I'm <strong>Vaishnavi Agrawal</strong>, a passionate and driven student at KLE Technological University, currently specializing in Generative AI. With a deep curiosity for machine learning and artificial intelligence, I am focused on exploring how these technologies can revolutionize industries and improve human experiences.
    </p>
    <p>
        Through my academic journey and hands-on projects, I've gained a solid foundation in AI methodologies, neural networks, and data science, with a particular interest in generative models, deep learning, and their real-world applications.

    </p>
  </div>
  <section id="introduction" >


    <div style="display: flex; flex-direction: column;">
        <div style="text-align: center;">
            <img src="https://cdn.bap-software.net/2024/07/27001309/generative-AI.jpg"/ style="width:60%;">
        </div>
        <div style="padding:10px 60px; width:60%; margin:0 auto; ">
            <h1>Introduction</h1>
            <p>Generative AI, a subset of artificial intelligence, focuses on creating new content by learning patterns and structures from existing data. Leveraging advanced algorithms like deep learning, generative models can produce text, images, audio, videos, and even 3D designs that mimic human creativity. These systems use architectures such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformers like GPT (Generative Pre-trained Transformers) to understand and generate contextually relevant outputs. Their applications span various industries, from generating realistic artwork to developing conversational agents, offering immense possibilities for automation and innovation.</p>
        </div>
    </div>
    
  </section>

  <h1 style="text-align: center;">Course Project Report</h1>
  <section id="report" style="display: flex;" >
      <div class="pdf-container">
          <embed src="GEN_AI_REPORT.pdf" type="application/pdf" style="width: 60%; height: 90vh;">
          </div>
        </section>
        
<h1 style="text-align: center;">Course Project Presentation</h1>
<section id="ppt">
    <div class="pdf-container">
        <embed src="Gen_AI_PPT.pdf" type="application/pdf" style="width: 60%; height: 90vh;">
        </div>
    </section>
    
    <h1 style="text-align: center;">Results</h1>
  <section id="result" style="display: flex; flex-direction: column;">
    <div style="text-align: center;">
        <img src="./genRes1.jpg" style="width:60%;">
        <h4>Fig 1: Input of the beach image and three output variations are generated</h4>
        <img src="./genRes2.jpg" style="width:60%;">
        <h4>Fig 2: Input of Mona Lisa and three output variations are generated</h4>
    </div>

    <div>
        <h1>Code</h1>
        <pre>
            <code>
import requests
from io import BytesIO
from diffusers import StableDiffusionImageVariationPipeline
from PIL import Image
import torch
import torchvision.transforms as transforms

device = "cuda:0"
sd_pipe = StableDiffusionImageVariationPipeline.from_pretrained(
  "lambdalabs/sd-image-variations-diffusers",
  revision="v2.0",
)
sd_pipe = sd_pipe.to(device)

# Fetch the image from the URL
#image_url = "https://media.npr.org/assets/img/2012/02/02/mona-lisa-copy_custom-876888c0699fe7bd9ad55f7c974e59115683995e.jpg"
image_url = "https://cdn11.bigcommerce.com/s-x49po/images/stencil/1500x1500/products/82482/254612/1645383306204_IMG-0662__34833.1687160909.jpg?c=2"
response = requests.get(image_url)
im = Image.open(BytesIO(response.content))

# Image transformations
tform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize(
        (224, 224),
        interpolation=transforms.InterpolationMode.BICUBIC,
        antialias=False,
    ),
    transforms.Normalize(
      [0.48145466, 0.4578275, 0.40821073],
      [0.26862954, 0.26130258, 0.27577711]
    ),
])

inp = tform(im).to(device).unsqueeze(0)

# Generate and save multiple images
num_variations = 5  # Number of different results to generate

for i in range(num_variations):
    # Set a different seed for each iteration (optional)
    generator = torch.manual_seed(i)  # Change seed to get different results

    out = sd_pipe(inp, guidance_scale=3, generator=generator)

    # Save each result with a unique filename
    out["images"][0].save(f"result_{i+1}.jpg")
    print(f"Image result_{i+1}.jpg saved.")
            </code>
        </pre>
    </div>

    <div>
        <h1>Google Colab Integration</h1>
        <a href="https://colab.research.google.com/drive/1eweOD6AjH0udT6DQ7yZhLaEUm8oLPZyL?usp=sharing" 
            target="_blank" 
            class="button-link">
            Open in Google Colab
        </a>
    </div>
  </section>
</body>
</html>
